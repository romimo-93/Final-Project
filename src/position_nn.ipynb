{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd080c97f02d7c11e83bc363ff72acb071775dee1823dc2665fdbc0eaa45fc52472",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "source": [
    "## Import and Prep Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player data from URL\n",
    "results = requests.get(\"http://nhl-app.eba-tmaqptju.us-west-2.elasticbeanstalk.com/api/avgplayerstats/all\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataframe of player data\n",
    "df = pd.DataFrame()\n",
    "pos_list = []\n",
    "toi_list = []\n",
    "g_list = []\n",
    "a_list = []\n",
    "s_list = []\n",
    "h_list = []\n",
    "ppg_list = []\n",
    "ppa_list = []\n",
    "pim_list = []\n",
    "fow_list = []\n",
    "fot_list = []\n",
    "ta_list = []\n",
    "ga_list = []\n",
    "shg_list = []\n",
    "sha_list = []\n",
    "bs_list = []\n",
    "etoi_list = []\n",
    "shtoi_list = []\n",
    "pptoi_list = []\n",
    "for player in results:\n",
    "    pos_list.append(player['Position'][-1])\n",
    "    toi_list.append(player['timeOnIce'])\n",
    "    a_list.append(player['assists'])\n",
    "    g_list.append(player['goals'])\n",
    "    s_list.append(player['shots'])\n",
    "    h_list.append(player['hits'])\n",
    "    ppg_list.append(player['powerPlayGoals'])\n",
    "    ppa_list.append(player['powerPlayAssists'])\n",
    "    pim_list.append(player['penaltyMinutes'])\n",
    "    fow_list.append(player['faceOffWins'])\n",
    "    fot_list.append(player['faceoffTaken'])\n",
    "    ta_list.append(player['takeaways'])\n",
    "    ga_list.append(player['Expr1'])\n",
    "    shg_list.append(player['shortHandedGoals'])\n",
    "    sha_list.append(player['shortHandedAssists'])\n",
    "    bs_list.append(player['blocked'])\n",
    "    etoi_list.append(player['evenTimeOnIce'])\n",
    "    shtoi_list.append(player['shortHandedTimeOnIce'])\n",
    "    pptoi_list.append(player['powerPlayTimeOnIce'])\n",
    "df[\"pos\"] = pos_list\n",
    "df[\"toi\"] = toi_list\n",
    "df[\"g\"] = g_list\n",
    "df[\"a\"] = g_list\n",
    "df[\"s\"] = s_list\n",
    "df[\"h\"] = h_list\n",
    "df[\"ppg\"] = ppg_list\n",
    "df[\"ppa\"] = ppa_list\n",
    "df[\"pim\"] = pim_list\n",
    "df[\"fow\"] = fow_list\n",
    "df[\"fot\"] = fot_list\n",
    "df[\"ta\"] = ta_list\n",
    "df[\"ga\"] = ga_list\n",
    "df[\"shg\"] = shg_list\n",
    "df[\"sha\"] = sha_list\n",
    "df[\"bs\"] = bs_list\n",
    "df[\"etoi\"] = etoi_list\n",
    "df[\"shtoi\"] = shtoi_list\n",
    "df[\"pptoi\"] = pptoi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     pos          toi         g         a         s         h       ppg  \\\n",
       "0      W   942.829384  0.308057  0.308057  2.308057  0.848341  0.090047   \n",
       "1      W   475.555556  0.000000  0.000000  0.555556  1.277778  0.000000   \n",
       "2      W   473.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      D  1019.128079  0.034483  0.034483  0.852217  1.842365  0.000000   \n",
       "4      W   421.500000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...   ..          ...       ...       ...       ...       ...       ...   \n",
       "3348   D  1078.284483  0.094828  0.094828  1.172414  0.000000  0.025862   \n",
       "3349   W   666.337209  0.127907  0.127907  1.418605  0.000000  0.000000   \n",
       "3350   D   680.400000  0.000000  0.000000  0.885714  0.742857  0.000000   \n",
       "3351   W   935.103093  0.194158  0.194158  1.718213  0.000000  0.063574   \n",
       "3352   C   680.024242  0.103030  0.103030  1.109091  0.363636  0.012121   \n",
       "\n",
       "           ppa       pim       fow       fot        ta        ga       shg  \\\n",
       "0     0.063981  0.272512  0.132701  0.478673  0.502370  0.308057  0.000000   \n",
       "1     0.000000  3.611111  0.000000  0.000000  0.111111  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.527094  0.000000  0.004926  0.231527  0.034483  0.000000   \n",
       "4     0.000000  1.000000  0.000000  0.500000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3348  0.077586  0.603448  0.000000  0.000000  0.000000  0.094828  0.000000   \n",
       "3349  0.023256  0.488372  0.081395  0.337209  0.000000  0.127907  0.000000   \n",
       "3350  0.000000  0.342857  0.000000  0.000000  0.171429  0.000000  0.000000   \n",
       "3351  0.061856  0.527491  0.041237  0.118557  0.000000  0.194158  0.006873   \n",
       "3352  0.030303  0.206061  2.987879  6.551515  0.284848  0.103030  0.000000   \n",
       "\n",
       "           sha        bs        etoi       shtoi       pptoi  \n",
       "0     0.000000  0.355450  795.374408    5.945498  141.509479  \n",
       "1     0.000000  0.111111  471.777778    0.333333    3.444444  \n",
       "2     0.000000  0.000000  390.000000    0.000000   83.000000  \n",
       "3     0.014778  1.507389  911.556650  104.167488    3.403941  \n",
       "4     0.000000  0.000000  383.000000   14.000000   24.500000  \n",
       "...        ...       ...         ...         ...         ...  \n",
       "3348  0.017241  0.000000  872.448276   84.965517  120.870690  \n",
       "3349  0.000000  0.000000  624.209302    3.418605   38.709302  \n",
       "3350  0.000000  0.428571  656.228571   20.685714    3.485714  \n",
       "3351  0.000000  0.000000  736.018900   38.810997  160.273196  \n",
       "3352  0.000000  0.212121  606.533333    2.860606   70.630303  \n",
       "\n",
       "[3353 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pos</th>\n      <th>toi</th>\n      <th>g</th>\n      <th>a</th>\n      <th>s</th>\n      <th>h</th>\n      <th>ppg</th>\n      <th>ppa</th>\n      <th>pim</th>\n      <th>fow</th>\n      <th>fot</th>\n      <th>ta</th>\n      <th>ga</th>\n      <th>shg</th>\n      <th>sha</th>\n      <th>bs</th>\n      <th>etoi</th>\n      <th>shtoi</th>\n      <th>pptoi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>W</td>\n      <td>942.829384</td>\n      <td>0.308057</td>\n      <td>0.308057</td>\n      <td>2.308057</td>\n      <td>0.848341</td>\n      <td>0.090047</td>\n      <td>0.063981</td>\n      <td>0.272512</td>\n      <td>0.132701</td>\n      <td>0.478673</td>\n      <td>0.502370</td>\n      <td>0.308057</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.355450</td>\n      <td>795.374408</td>\n      <td>5.945498</td>\n      <td>141.509479</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>W</td>\n      <td>475.555556</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.555556</td>\n      <td>1.277778</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.611111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>471.777778</td>\n      <td>0.333333</td>\n      <td>3.444444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>W</td>\n      <td>473.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>390.000000</td>\n      <td>0.000000</td>\n      <td>83.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>1019.128079</td>\n      <td>0.034483</td>\n      <td>0.034483</td>\n      <td>0.852217</td>\n      <td>1.842365</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.527094</td>\n      <td>0.000000</td>\n      <td>0.004926</td>\n      <td>0.231527</td>\n      <td>0.034483</td>\n      <td>0.000000</td>\n      <td>0.014778</td>\n      <td>1.507389</td>\n      <td>911.556650</td>\n      <td>104.167488</td>\n      <td>3.403941</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>W</td>\n      <td>421.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>383.000000</td>\n      <td>14.000000</td>\n      <td>24.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3348</th>\n      <td>D</td>\n      <td>1078.284483</td>\n      <td>0.094828</td>\n      <td>0.094828</td>\n      <td>1.172414</td>\n      <td>0.000000</td>\n      <td>0.025862</td>\n      <td>0.077586</td>\n      <td>0.603448</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.094828</td>\n      <td>0.000000</td>\n      <td>0.017241</td>\n      <td>0.000000</td>\n      <td>872.448276</td>\n      <td>84.965517</td>\n      <td>120.870690</td>\n    </tr>\n    <tr>\n      <th>3349</th>\n      <td>W</td>\n      <td>666.337209</td>\n      <td>0.127907</td>\n      <td>0.127907</td>\n      <td>1.418605</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023256</td>\n      <td>0.488372</td>\n      <td>0.081395</td>\n      <td>0.337209</td>\n      <td>0.000000</td>\n      <td>0.127907</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>624.209302</td>\n      <td>3.418605</td>\n      <td>38.709302</td>\n    </tr>\n    <tr>\n      <th>3350</th>\n      <td>D</td>\n      <td>680.400000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.885714</td>\n      <td>0.742857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.342857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.171429</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.428571</td>\n      <td>656.228571</td>\n      <td>20.685714</td>\n      <td>3.485714</td>\n    </tr>\n    <tr>\n      <th>3351</th>\n      <td>W</td>\n      <td>935.103093</td>\n      <td>0.194158</td>\n      <td>0.194158</td>\n      <td>1.718213</td>\n      <td>0.000000</td>\n      <td>0.063574</td>\n      <td>0.061856</td>\n      <td>0.527491</td>\n      <td>0.041237</td>\n      <td>0.118557</td>\n      <td>0.000000</td>\n      <td>0.194158</td>\n      <td>0.006873</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>736.018900</td>\n      <td>38.810997</td>\n      <td>160.273196</td>\n    </tr>\n    <tr>\n      <th>3352</th>\n      <td>C</td>\n      <td>680.024242</td>\n      <td>0.103030</td>\n      <td>0.103030</td>\n      <td>1.109091</td>\n      <td>0.363636</td>\n      <td>0.012121</td>\n      <td>0.030303</td>\n      <td>0.206061</td>\n      <td>2.987879</td>\n      <td>6.551515</td>\n      <td>0.284848</td>\n      <td>0.103030</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.212121</td>\n      <td>606.533333</td>\n      <td>2.860606</td>\n      <td>70.630303</td>\n    </tr>\n  </tbody>\n</table>\n<p>3353 rows Ã— 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.drop(columns=[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish X, y\n",
    "X = X_df.values\n",
    "y = df[\"pos\"]"
   ]
  },
  {
   "source": [
    "## Create Training and Testing sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Player Positions (C, W, D) to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "encoded_y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CLASSES\n",
    "# 0 - C (Center)\n",
    "# 1 - D (Defense)\n",
    "# 2 - W (Winger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test splits\n",
    "X_train, X_test, y_uncat_train, y_uncat_test = train_test_split(X, encoded_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the y -- One-Hot Encoding\n",
    "y_train = to_categorical(y_uncat_train)\n",
    "y_test = to_categorical(y_uncat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the columns\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2514, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "source": [
    "## Build a Deep Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependecies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the columns of the training data\n",
    "model.add(Dense(18, activation=\"relu\", input_dim=X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(10, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(10, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "model.add(Dense(units=y_train.shape[1], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "79/79 - 0s - loss: 0.9050 - accuracy: 0.5664\n",
      "Epoch 2/100\n",
      "79/79 - 0s - loss: 0.7010 - accuracy: 0.6901\n",
      "Epoch 3/100\n",
      "79/79 - 0s - loss: 0.5621 - accuracy: 0.8194\n",
      "Epoch 4/100\n",
      "79/79 - 0s - loss: 0.4648 - accuracy: 0.8373\n",
      "Epoch 5/100\n",
      "79/79 - 0s - loss: 0.4194 - accuracy: 0.8508\n",
      "Epoch 6/100\n",
      "79/79 - 0s - loss: 0.4019 - accuracy: 0.8524\n",
      "Epoch 7/100\n",
      "79/79 - 0s - loss: 0.3917 - accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "79/79 - 0s - loss: 0.3834 - accuracy: 0.8548\n",
      "Epoch 9/100\n",
      "79/79 - 0s - loss: 0.3764 - accuracy: 0.8596\n",
      "Epoch 10/100\n",
      "79/79 - 0s - loss: 0.3724 - accuracy: 0.8576\n",
      "Epoch 11/100\n",
      "79/79 - 0s - loss: 0.3676 - accuracy: 0.8596\n",
      "Epoch 12/100\n",
      "79/79 - 0s - loss: 0.3641 - accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "79/79 - 0s - loss: 0.3605 - accuracy: 0.8608\n",
      "Epoch 14/100\n",
      "79/79 - 0s - loss: 0.3579 - accuracy: 0.8616\n",
      "Epoch 15/100\n",
      "79/79 - 0s - loss: 0.3557 - accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "79/79 - 0s - loss: 0.3523 - accuracy: 0.8620\n",
      "Epoch 17/100\n",
      "79/79 - 0s - loss: 0.3495 - accuracy: 0.8620\n",
      "Epoch 18/100\n",
      "79/79 - 0s - loss: 0.3486 - accuracy: 0.8592\n",
      "Epoch 19/100\n",
      "79/79 - 0s - loss: 0.3465 - accuracy: 0.8624\n",
      "Epoch 20/100\n",
      "79/79 - 0s - loss: 0.3459 - accuracy: 0.8628\n",
      "Epoch 21/100\n",
      "79/79 - 0s - loss: 0.3464 - accuracy: 0.8620\n",
      "Epoch 22/100\n",
      "79/79 - 0s - loss: 0.3407 - accuracy: 0.8671\n",
      "Epoch 23/100\n",
      "79/79 - 0s - loss: 0.3397 - accuracy: 0.8648\n",
      "Epoch 24/100\n",
      "79/79 - 0s - loss: 0.3367 - accuracy: 0.8644\n",
      "Epoch 25/100\n",
      "79/79 - 0s - loss: 0.3366 - accuracy: 0.8652\n",
      "Epoch 26/100\n",
      "79/79 - 0s - loss: 0.3358 - accuracy: 0.8675\n",
      "Epoch 27/100\n",
      "79/79 - 0s - loss: 0.3318 - accuracy: 0.8644\n",
      "Epoch 28/100\n",
      "79/79 - 0s - loss: 0.3315 - accuracy: 0.8656\n",
      "Epoch 29/100\n",
      "79/79 - 0s - loss: 0.3289 - accuracy: 0.8671\n",
      "Epoch 30/100\n",
      "79/79 - 0s - loss: 0.3293 - accuracy: 0.8675\n",
      "Epoch 31/100\n",
      "79/79 - 0s - loss: 0.3268 - accuracy: 0.8648\n",
      "Epoch 32/100\n",
      "79/79 - 0s - loss: 0.3258 - accuracy: 0.8675\n",
      "Epoch 33/100\n",
      "79/79 - 0s - loss: 0.3245 - accuracy: 0.8671\n",
      "Epoch 34/100\n",
      "79/79 - 0s - loss: 0.3230 - accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "79/79 - 0s - loss: 0.3216 - accuracy: 0.8711\n",
      "Epoch 36/100\n",
      "79/79 - 0s - loss: 0.3202 - accuracy: 0.8691\n",
      "Epoch 37/100\n",
      "79/79 - 0s - loss: 0.3177 - accuracy: 0.8671\n",
      "Epoch 38/100\n",
      "79/79 - 0s - loss: 0.3182 - accuracy: 0.8687\n",
      "Epoch 39/100\n",
      "79/79 - 0s - loss: 0.3194 - accuracy: 0.8671\n",
      "Epoch 40/100\n",
      "79/79 - 0s - loss: 0.3151 - accuracy: 0.8699\n",
      "Epoch 41/100\n",
      "79/79 - 0s - loss: 0.3127 - accuracy: 0.8695\n",
      "Epoch 42/100\n",
      "79/79 - 0s - loss: 0.3121 - accuracy: 0.8711\n",
      "Epoch 43/100\n",
      "79/79 - 0s - loss: 0.3119 - accuracy: 0.8707\n",
      "Epoch 44/100\n",
      "79/79 - 0s - loss: 0.3107 - accuracy: 0.8731\n",
      "Epoch 45/100\n",
      "79/79 - 0s - loss: 0.3083 - accuracy: 0.8715\n",
      "Epoch 46/100\n",
      "79/79 - 0s - loss: 0.3064 - accuracy: 0.8707\n",
      "Epoch 47/100\n",
      "79/79 - 0s - loss: 0.3058 - accuracy: 0.8751\n",
      "Epoch 48/100\n",
      "79/79 - 0s - loss: 0.3035 - accuracy: 0.8723\n",
      "Epoch 49/100\n",
      "79/79 - 0s - loss: 0.3044 - accuracy: 0.8731\n",
      "Epoch 50/100\n",
      "79/79 - 0s - loss: 0.3022 - accuracy: 0.8723\n",
      "Epoch 51/100\n",
      "79/79 - 0s - loss: 0.3012 - accuracy: 0.8751\n",
      "Epoch 52/100\n",
      "79/79 - 0s - loss: 0.3024 - accuracy: 0.8763\n",
      "Epoch 53/100\n",
      "79/79 - 0s - loss: 0.3011 - accuracy: 0.8755\n",
      "Epoch 54/100\n",
      "79/79 - 0s - loss: 0.2997 - accuracy: 0.8771\n",
      "Epoch 55/100\n",
      "79/79 - 0s - loss: 0.2983 - accuracy: 0.8759\n",
      "Epoch 56/100\n",
      "79/79 - 0s - loss: 0.2974 - accuracy: 0.8751\n",
      "Epoch 57/100\n",
      "79/79 - 0s - loss: 0.2950 - accuracy: 0.8787\n",
      "Epoch 58/100\n",
      "79/79 - 0s - loss: 0.2960 - accuracy: 0.8743\n",
      "Epoch 59/100\n",
      "79/79 - 0s - loss: 0.2947 - accuracy: 0.8787\n",
      "Epoch 60/100\n",
      "79/79 - 0s - loss: 0.2961 - accuracy: 0.8775\n",
      "Epoch 61/100\n",
      "79/79 - 0s - loss: 0.2932 - accuracy: 0.8771\n",
      "Epoch 62/100\n",
      "79/79 - 0s - loss: 0.2909 - accuracy: 0.8775\n",
      "Epoch 63/100\n",
      "79/79 - 0s - loss: 0.2937 - accuracy: 0.8775\n",
      "Epoch 64/100\n",
      "79/79 - 0s - loss: 0.2919 - accuracy: 0.8755\n",
      "Epoch 65/100\n",
      "79/79 - 0s - loss: 0.2924 - accuracy: 0.8799\n",
      "Epoch 66/100\n",
      "79/79 - 0s - loss: 0.2872 - accuracy: 0.8835\n",
      "Epoch 67/100\n",
      "79/79 - 0s - loss: 0.2890 - accuracy: 0.8795\n",
      "Epoch 68/100\n",
      "79/79 - 0s - loss: 0.2869 - accuracy: 0.8791\n",
      "Epoch 69/100\n",
      "79/79 - 0s - loss: 0.2881 - accuracy: 0.8795\n",
      "Epoch 70/100\n",
      "79/79 - 0s - loss: 0.2848 - accuracy: 0.8779\n",
      "Epoch 71/100\n",
      "79/79 - 0s - loss: 0.2832 - accuracy: 0.8807\n",
      "Epoch 72/100\n",
      "79/79 - 0s - loss: 0.2840 - accuracy: 0.8791\n",
      "Epoch 73/100\n",
      "79/79 - 0s - loss: 0.2847 - accuracy: 0.8807\n",
      "Epoch 74/100\n",
      "79/79 - 0s - loss: 0.2828 - accuracy: 0.8759\n",
      "Epoch 75/100\n",
      "79/79 - 0s - loss: 0.2833 - accuracy: 0.8783\n",
      "Epoch 76/100\n",
      "79/79 - 0s - loss: 0.2786 - accuracy: 0.8858\n",
      "Epoch 77/100\n",
      "79/79 - 0s - loss: 0.2797 - accuracy: 0.8819\n",
      "Epoch 78/100\n",
      "79/79 - 0s - loss: 0.2800 - accuracy: 0.8791\n",
      "Epoch 79/100\n",
      "79/79 - 0s - loss: 0.2794 - accuracy: 0.8819\n",
      "Epoch 80/100\n",
      "79/79 - 0s - loss: 0.2780 - accuracy: 0.8779\n",
      "Epoch 81/100\n",
      "79/79 - 0s - loss: 0.2757 - accuracy: 0.8807\n",
      "Epoch 82/100\n",
      "79/79 - 0s - loss: 0.2748 - accuracy: 0.8850\n",
      "Epoch 83/100\n",
      "79/79 - 0s - loss: 0.2770 - accuracy: 0.8823\n",
      "Epoch 84/100\n",
      "79/79 - 0s - loss: 0.2745 - accuracy: 0.8823\n",
      "Epoch 85/100\n",
      "79/79 - 0s - loss: 0.2753 - accuracy: 0.8783\n",
      "Epoch 86/100\n",
      "79/79 - 0s - loss: 0.2751 - accuracy: 0.8815\n",
      "Epoch 87/100\n",
      "79/79 - 0s - loss: 0.2792 - accuracy: 0.8815\n",
      "Epoch 88/100\n",
      "79/79 - 0s - loss: 0.2728 - accuracy: 0.8807\n",
      "Epoch 89/100\n",
      "79/79 - 0s - loss: 0.2716 - accuracy: 0.8842\n",
      "Epoch 90/100\n",
      "79/79 - 0s - loss: 0.2698 - accuracy: 0.8846\n",
      "Epoch 91/100\n",
      "79/79 - 0s - loss: 0.2725 - accuracy: 0.8815\n",
      "Epoch 92/100\n",
      "79/79 - 0s - loss: 0.2703 - accuracy: 0.8803\n",
      "Epoch 93/100\n",
      "79/79 - 0s - loss: 0.2712 - accuracy: 0.8819\n",
      "Epoch 94/100\n",
      "79/79 - 0s - loss: 0.2685 - accuracy: 0.8819\n",
      "Epoch 95/100\n",
      "79/79 - 0s - loss: 0.2722 - accuracy: 0.8823\n",
      "Epoch 96/100\n",
      "79/79 - 0s - loss: 0.2702 - accuracy: 0.8795\n",
      "Epoch 97/100\n",
      "79/79 - 0s - loss: 0.2690 - accuracy: 0.8846\n",
      "Epoch 98/100\n",
      "79/79 - 0s - loss: 0.2698 - accuracy: 0.8807\n",
      "Epoch 99/100\n",
      "79/79 - 0s - loss: 0.2673 - accuracy: 0.8831\n",
      "Epoch 100/100\n",
      "79/79 - 0s - loss: 0.2663 - accuracy: 0.8815\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21c2038fc40>"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "source": [
    "## Evaluate the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27/27 - 0s - loss: 0.4159 - accuracy: 0.8534\n",
      "Loss: 0.4159456193447113, Accuracy: 0.8533968925476074\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row to test\n",
    "row = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 1.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Actual Class\n",
    "y_test[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_test[row], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted class: [1]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "print(f\"Predicted class: {np.argmax(model.predict(test), axis=-1)}\")"
   ]
  },
  {
   "source": [
    "## Save the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"position_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}